{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np # for transformation\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from os.path import exists\n",
    "\n",
    "import torch # PyTorch package\n",
    "import torchvision # load datasets\n",
    "import torchvision.transforms as transforms # transform data\n",
    "import torch.nn as nn # basic building block for neural neteorks\n",
    "import torch.nn.functional as F # import convolution functions like Relu\n",
    "import torch.optim as optim # optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data into a python dictionary\n",
    "train_data = pd.read_json(\"train_data.json\")\n",
    "\n",
    "#print(train_data)\n",
    "\n",
    "# Clean out the games that have no reviews\n",
    "train_df = train_data.dropna(subset=[\"sentiment\"])\n",
    "\n",
    "# explode the dataset\n",
    "train_df_expanded=train_df.explode(\"screenshots\", ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>release</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviews</th>\n",
       "      <th>percentage</th>\n",
       "      <th>tags</th>\n",
       "      <th>screenshots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2460480</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>KILL CRAB</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[3D, Action, Action-Adventure, Adventure, Atmo...</td>\n",
       "      <td>2460480_ss_7d0cc1ba5160475a863d3cab18ae20c5319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2460480</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>KILL CRAB</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[3D, Action, Action-Adventure, Adventure, Atmo...</td>\n",
       "      <td>2460480_ss_ed40cec9267023b99fb3bf571a5c74556bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2460480</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>KILL CRAB</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[3D, Action, Action-Adventure, Adventure, Atmo...</td>\n",
       "      <td>2460480_ss_ef88923d635e37c1a63ff2658f11a0ed489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2460480</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>KILL CRAB</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[3D, Action, Action-Adventure, Adventure, Atmo...</td>\n",
       "      <td>2460480_ss_f46c745c81786d4a8aa18187f2d942aff7a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2460480</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>KILL CRAB</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[3D, Action, Action-Adventure, Adventure, Atmo...</td>\n",
       "      <td>2460480_ss_f8008bc1bc867afb00beb2e8844d6386e32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41786</th>\n",
       "      <td>2684300</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Just skill shooter 2</td>\n",
       "      <td>2140</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[Action, Action RPG, Arcade, FPS, First-Person...</td>\n",
       "      <td>2684300_ss_46ae97a9290948442fcb2418af5c161f856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41787</th>\n",
       "      <td>2684300</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Just skill shooter 2</td>\n",
       "      <td>2140</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[Action, Action RPG, Arcade, FPS, First-Person...</td>\n",
       "      <td>2684300_ss_9031aae2fe1d233dbcc1269a2486fd86d87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41788</th>\n",
       "      <td>2684300</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Just skill shooter 2</td>\n",
       "      <td>2140</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[Action, Action RPG, Arcade, FPS, First-Person...</td>\n",
       "      <td>2684300_ss_a182b3e3e54a88360f3d0ec05efd8d64a28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41789</th>\n",
       "      <td>2684300</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Just skill shooter 2</td>\n",
       "      <td>2140</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[Action, Action RPG, Arcade, FPS, First-Person...</td>\n",
       "      <td>2684300_ss_b61bdccd5592ed797378e1a50985c6eb45c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41790</th>\n",
       "      <td>2684300</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Just skill shooter 2</td>\n",
       "      <td>2140</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[Action, Action RPG, Arcade, FPS, First-Person...</td>\n",
       "      <td>2684300_ss_f85830c003694d9888f7e70bedfe90091ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41791 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid     release                 title  price        sentiment  \\\n",
       "0      2460480  2023-07-19             KILL CRAB      0    Very Positive   \n",
       "1      2460480  2023-07-19             KILL CRAB      0    Very Positive   \n",
       "2      2460480  2023-07-19             KILL CRAB      0    Very Positive   \n",
       "3      2460480  2023-07-19             KILL CRAB      0    Very Positive   \n",
       "4      2460480  2023-07-19             KILL CRAB      0    Very Positive   \n",
       "...        ...         ...                   ...    ...              ...   \n",
       "41786  2684300  2024-01-04  Just skill shooter 2   2140  Mostly Positive   \n",
       "41787  2684300  2024-01-04  Just skill shooter 2   2140  Mostly Positive   \n",
       "41788  2684300  2024-01-04  Just skill shooter 2   2140  Mostly Positive   \n",
       "41789  2684300  2024-01-04  Just skill shooter 2   2140  Mostly Positive   \n",
       "41790  2684300  2024-01-04  Just skill shooter 2   2140  Mostly Positive   \n",
       "\n",
       "       reviews  percentage                                               tags  \\\n",
       "0         77.0        81.0  [3D, Action, Action-Adventure, Adventure, Atmo...   \n",
       "1         77.0        81.0  [3D, Action, Action-Adventure, Adventure, Atmo...   \n",
       "2         77.0        81.0  [3D, Action, Action-Adventure, Adventure, Atmo...   \n",
       "3         77.0        81.0  [3D, Action, Action-Adventure, Adventure, Atmo...   \n",
       "4         77.0        81.0  [3D, Action, Action-Adventure, Adventure, Atmo...   \n",
       "...        ...         ...                                                ...   \n",
       "41786     17.0        70.0  [Action, Action RPG, Arcade, FPS, First-Person...   \n",
       "41787     17.0        70.0  [Action, Action RPG, Arcade, FPS, First-Person...   \n",
       "41788     17.0        70.0  [Action, Action RPG, Arcade, FPS, First-Person...   \n",
       "41789     17.0        70.0  [Action, Action RPG, Arcade, FPS, First-Person...   \n",
       "41790     17.0        70.0  [Action, Action RPG, Arcade, FPS, First-Person...   \n",
       "\n",
       "                                             screenshots  \n",
       "0      2460480_ss_7d0cc1ba5160475a863d3cab18ae20c5319...  \n",
       "1      2460480_ss_ed40cec9267023b99fb3bf571a5c74556bb...  \n",
       "2      2460480_ss_ef88923d635e37c1a63ff2658f11a0ed489...  \n",
       "3      2460480_ss_f46c745c81786d4a8aa18187f2d942aff7a...  \n",
       "4      2460480_ss_f8008bc1bc867afb00beb2e8844d6386e32...  \n",
       "...                                                  ...  \n",
       "41786  2684300_ss_46ae97a9290948442fcb2418af5c161f856...  \n",
       "41787  2684300_ss_9031aae2fe1d233dbcc1269a2486fd86d87...  \n",
       "41788  2684300_ss_a182b3e3e54a88360f3d0ec05efd8d64a28...  \n",
       "41789  2684300_ss_b61bdccd5592ed797378e1a50985c6eb45c...  \n",
       "41790  2684300_ss_f85830c003694d9888f7e70bedfe90091ca...  \n",
       "\n",
       "[41791 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['appid', 'release', 'title', 'price', 'sentiment', 'reviews',\n",
      "       'percentage', 'tags', 'screenshots'],\n",
      "      dtype='object')\n",
      "sentiment\n",
      "Positive                   1650\n",
      "Very Positive              1148\n",
      "Mixed                       736\n",
      "Mostly Positive             664\n",
      "Overwhelmingly Positive     109\n",
      "Mostly Negative              89\n",
      "Negative                      8\n",
      "Very Negative                 1\n",
      "Name: count, dtype: int64\n",
      "No value has a count of 2.\n"
     ]
    }
   ],
   "source": [
    "# Exploration and minor cleaning\n",
    "print(train_data.columns)\n",
    "\n",
    "print(train_data[\"sentiment\"].value_counts())\n",
    "\n",
    "dupe = train_data[\"appid\"].value_counts()\n",
    "if 2 in dupe.values:\n",
    "    print(\"There is at least one value with a count of 2.\")\n",
    "else:\n",
    "    print(\"No value has a count of 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After this part it gets memory intensive, I have 16GB and it doesn't work so I used the external python script to make the images 256 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transformation funciton\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5))\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a PIL image and transforms\n",
    "train_df_expanded[\"images\"] = None\n",
    "for i in range(len(train_df_expanded[\"screenshots\"])//2):\n",
    "    screenshot_filename = train_df_expanded[\"screenshots\"][i]\n",
    "    image_path = f\"C:/Users/Beste/Desktop/AAB/images/{screenshot_filename}\"\n",
    "    if exists(image_path):\n",
    "        with Image.open(image_path) as image:\n",
    "            image = image.convert('RGB')\n",
    "            transformed_image = transform(image)\n",
    "            train_df_expanded.at[i, \"images\"] = transformed_image\n",
    "\n",
    "# Clean out the games that have no image\n",
    "train_df_expanded = train_df_expanded.dropna(subset=[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files categorized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create different files\n",
    "def categorize_files(dataframe, source_folder, destination_folder):\n",
    "    # Create destination folders if they don't exist\n",
    "    categories = dataframe['sentiment'].unique()\n",
    "    for category in categories:\n",
    "        category_folder = os.path.join(destination_folder, category)\n",
    "        if not os.path.exists(category_folder):\n",
    "            os.makedirs(category_folder)\n",
    "\n",
    "    # Iterate through rows in the DataFrame\n",
    "    for index, row in dataframe.iterrows():\n",
    "        filename = row['screenshots']\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        if os.path.isfile(source_file):\n",
    "            category = row['sentiment']\n",
    "            destination_folder_category = os.path.join(destination_folder, category)\n",
    "            shutil.copy(source_file, destination_folder_category)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Path to the big folder containing files to categorize\n",
    "    source_folder = \"C:/Users/Beste/Desktop/AAB/images\"\n",
    "\n",
    "    # Path to the folder where categorized files will be placed\n",
    "    destination_folder = \"C:/Users/Beste/Desktop/AAB/train\"\n",
    "\n",
    "    categorize_files(train_df_expanded, source_folder, destination_folder)\n",
    "    print(\"Files categorized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Beste/Desktop/AAB/images\\\\1623120'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Iterate over batches of data using a for loop\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Call function on your images here\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Print the class of each image in the batch\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Beste\\Documents\\AdvancedAnalytics_Steam_images_DL\\image_class.py:19\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m     20\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32mc:\\Users\\Beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Beste/Desktop/AAB/images\\\\1623120'"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    ''' function to show image '''\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()  # convert to numpy objects\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Iterate over batches of data using a for loop\n",
    "for images, labels in train_loader:\n",
    "    # Call function on your images here\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "    # Print the class of each image in the batch\n",
    "    batch_size = images.size(0)\n",
    "    print(' '.join('%s' % classes[labels[j]] for j in range(batch_size)))\n",
    "    break  # Exit the loop after displaying the first batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
